#!/usr/bin/env python3
# log_archive_setup.py
# One-shot setup script.
# It installs a cron-driven worker that:
# - archives /var/log/siem/*.log to /var/log/siem/archive/
# - calculates per-line SHA256 hashes
# - stores archive-level SHA256
# - encrypts archives using SOC recipient PUBLIC key (GPG)
# - deletes plaintext logs after successful encryption
# - restarts ONLY the selected kuma-agent-%id%.service

import os
import re
import sys
import shutil
import subprocess
import tempfile
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Optional, Tuple


# -------------------------
# Fixed paths/config
# -------------------------
LOG_DIR = Path("/var/log/siem")
ARCHIVE_DIR = LOG_DIR / "archive"

KEY_EXPORT_DIR = Path("/root/log-archive-keys")
FINGERPRINT_FILE = KEY_EXPORT_DIR / "recipient_fingerprint.txt"
PUBKEY_FILE = KEY_EXPORT_DIR / "recipient_pubkey.asc"
SECKEY_FILE = KEY_EXPORT_DIR / "recipient_seckey.asc"

SOC_KEY_UID = "log-archive@local"

KEY_NAME = "Log Archive Recipient"
KEY_EMAIL = SOC_KEY_UID
KEY_COMMENT = "Generated by log_archive_setup.py"
KEY_EXPIRE = "2y"

WORKER_DIR = Path("/usr/local/sbin")
CRON_DIR = Path("/etc/cron.d")


# -------------------------
# Output helpers
# -------------------------
def stage(msg: str) -> None:
    print(f"==> {msg}")


def ok(msg: str) -> None:
    print(f"    [OK] {msg}")


def warn(msg: str) -> None:
    print(f"    [WARN] {msg}")


def die(msg: str, code: int = 1) -> None:
    print(f"    [FAIL] {msg}", file=sys.stderr)
    sys.exit(code)


def require_root() -> None:
    if os.geteuid() != 0:
        die("Run as root (required to write /etc/cron.d and /usr/local/sbin).")


def which_or_die(bin_name: str) -> str:
    p = shutil.which(bin_name)
    if not p:
        die(f"Missing dependency: {bin_name}. Install it and re-run.")
    return p


def run(cmd, input_text: Optional[str] = None, env=None, check: bool = True, capture: bool = True):
    return subprocess.run(
        cmd,
        input=input_text,
        text=True,
        env=env,
        capture_output=capture,
        check=check
    )


def ensure_dir(path: Path, mode: int) -> None:
    path.mkdir(parents=True, exist_ok=True)
    os.chmod(path, mode)


def write_file(path: Path, content: str, mode: int) -> None:
    path.write_text(content, encoding="utf-8")
    os.chmod(path, mode)


def file_exists_and_nonempty(path: Path) -> bool:
    return path.exists() and path.is_file() and path.stat().st_size > 0


def prompt(msg: str, default: Optional[str] = None) -> str:
    if default is not None:
        s = input(f"{msg} [{default}]: ").strip()
        return s if s else default
    return input(f"{msg}: ").strip()


def confirm_yes(msg: str, default_no: bool = True) -> bool:
    suffix = " [y/N]" if default_no else " [Y/n]"
    ans = input(f"{msg}{suffix}: ").strip().lower()
    if not ans:
        return not default_no
    return ans in ("y", "yes")


def systemd_unit_exists(unit: str) -> bool:
    p = subprocess.run(["systemctl", "status", unit], capture_output=True, text=True)
    out = (p.stdout or "") + (p.stderr or "")
    if "Loaded: not-found" in out or "could not be found" in out.lower():
        return False
    return "Loaded:" in out and "not-found" not in out


def sanitize_id(raw_id: str) -> str:
    if not raw_id:
        die("Empty id.")
    if not re.match(r"^[A-Za-z0-9._-]+$", raw_id):
        die("Invalid id: allowed characters are A-Z a-z 0-9 . _ -")
    return raw_id
# -------------------------
# Worker template
# -------------------------
WORKER_TEMPLATE = r'''#!/usr/bin/env python3
import os
import sys
import subprocess
import hashlib
from pathlib import Path
from datetime import datetime

LOG_DIR = Path("__LOG_DIR__")
ARCHIVE_DIR = Path("__ARCHIVE_DIR__")

RECIPIENT_FPR = "__RECIPIENT_FPR__"
TARGET_SERVICE = "__TARGET_SERVICE__"

LOG_GLOB = "*.log"

def stage(msg):
    print(f"==> {msg}")

def run(cmd, *, check=True):
    return subprocess.run(cmd, text=True, capture_output=True, check=check)

def generate_line_hash_file(log_file):
    hash_file = log_file.with_suffix(log_file.suffix + ".sha256")

    with log_file.open("r", encoding="utf-8", errors="replace") as f_in, \
         hash_file.open("w", encoding="utf-8") as f_out:

        for idx, line in enumerate(f_in, 1):
            # Preserve exact original line without trailing newline
            original_event = line.rstrip("\n")

            # Compute hash over exact original line including newline
            h = hashlib.sha256(line.encode("utf-8")).hexdigest()

            # Write: <original event> <hash>  line <number>
            f_out.write(f"{original_event} {h}  line {idx}\n")

    return hash_file

def main():
    os.umask(0o077)

    args = sys.argv[1:]
    no_restart = "--no-restart" in args

    test_file = None
    if "--test-file" in args:
        i = args.index("--test-file")
        if i + 1 >= len(args):
            print("[FAIL] --test-file requires a path", file=sys.stderr)
            return 2
        test_file = Path(args[i + 1])

    if not LOG_DIR.exists():
        print(f"[FAIL] LOG_DIR not found: {LOG_DIR}", file=sys.stderr)
        return 2

    ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)
    os.chmod(ARCHIVE_DIR, 0o700)

    if test_file:
        files = [test_file] if test_file.exists() else []
    else:
        files = sorted([p for p in LOG_DIR.glob(LOG_GLOB) if p.is_file()])

    if not files:
        stage("No log files to process.")
    else:
        stage(f"Processing {len(files)} log file(s)")
        ts = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

        for log_file in files:
            if not log_file.exists():
                continue

            stage(f"Archiving & encrypting: {log_file.name}")

            archive_name = f"{log_file.stem}_{ts}.tar.gz"
            tar_tmp = ARCHIVE_DIR / f".{archive_name}.tmp"

            enc_name = f"{archive_name}.gpg"
            enc_tmp = ARCHIVE_DIR / f".{enc_name}.tmp"
            enc_final = ARCHIVE_DIR / enc_name

            sha_tmp = ARCHIVE_DIR / f".{enc_name}.sha256.tmp"
            sha_final = ARCHIVE_DIR / f"{enc_name}.sha256"

            try:
                hash_file = generate_line_hash_file(log_file)
                run(["tar", "-czf", str(tar_tmp), str(log_file), str(hash_file)])
            except subprocess.CalledProcessError as e:
                print(f"[FAIL] tar/line-hash failed: {e.stderr.strip()}", file=sys.stderr)
                continue

            try:
                run([
                    "gpg",
                    "--batch", "--yes",
                    "--trust-model", "always",
                    "--encrypt",
                    "--recipient", RECIPIENT_FPR,
                    "-o", str(enc_tmp),
                    str(tar_tmp),
                ])
            except subprocess.CalledProcessError as e:
                print(f"[FAIL] gpg encrypt failed: {e.stderr.strip()}", file=sys.stderr)
                tar_tmp.unlink(missing_ok=True)
                continue

            try:
                enc_tmp.replace(enc_final)

                h = hashlib.sha256()
                with open(enc_final, "rb") as f:
                    for chunk in iter(lambda: f.read(8192), b""):
                        h.update(chunk)

                with open(sha_tmp, "w") as hf:
                    hf.write(f"{h.hexdigest()}  {enc_final.name}\n")

                os.chmod(sha_tmp, 0o600)
                sha_tmp.replace(sha_final)

            except Exception as e:
                print(f"[FAIL] SHA256 generation failed: {e}", file=sys.stderr)
                continue

            try:
                tar_tmp.unlink(missing_ok=True)
                hash_file.unlink(missing_ok=True)
                log_file.unlink()
            except Exception as e:
                print(f"[WARN] cleanup issue: {e}", file=sys.stderr)

            print(f"[OK] {enc_final}")
            print(f"[OK] {sha_final}")

    if not no_restart:
        stage(f"Restarting service: {TARGET_SERVICE}")
        subprocess.run(["systemctl", "try-restart", TARGET_SERVICE])

    stage("Done.")
    return 0

if __name__ == "__main__":
    sys.exit(main())
'''

# -------------------------
# Setup: service choice
# -------------------------
def ask_target_service_id() -> Tuple[str, str]:
    stage("Step 0: Choose target service (kuma-agent-%id%)")
    raw = prompt("Enter %id% for kuma-agent-%id%")
    svc_id = sanitize_id(raw)
    unit = f"kuma-agent-{svc_id}.service"

    stage("Checking systemd unit existence")
    if not systemd_unit_exists(unit):
        warn(f"Unit {unit} not found. Similar units:")
        out = subprocess.run(
            ["systemctl", "list-units", "--type=service", "--all", "--no-pager"],
            capture_output=True,
            text=True
        )
        for line in out.stdout.splitlines():
            if "kuma-agent-" in line:
                print("   ", line.split()[0])
        die(f"Unit not found: {unit}. Fix the id and re-run.")
    ok(f"Selected service: {unit}")
    return svc_id, unit


# -------------------------
# Schedule parsing
# -------------------------
def parse_time_hhmm(time_str: str) -> Tuple[int, int]:
    m = re.match(r"^(\d{2}):(\d{2})$", time_str.strip())
    if not m:
        die("Time must be in HH:MM format.")
    hh = int(m.group(1))
    mm = int(m.group(2))
    if hh < 0 or hh > 23 or mm < 0 or mm > 59:
        die("Time out of range (00:00..23:59).")
    return hh, mm


def parse_weekdays(days_raw: str) -> str:
    days_raw = days_raw.strip()
    if not days_raw:
        die("Weekdays list is empty.")

    seen = set()
    out = []
    for item in days_raw.split(","):
        item = item.strip()
        if not item:
            continue
        if not item.isdigit():
            die(f"Invalid weekday value: {item}")
        di = int(item)
        if di < 1 or di > 7:
            die(f"Weekday out of range: {di} (must be 1..7)")
        cron_d = 0 if di == 7 else di
        if cron_d not in seen:
            seen.add(cron_d)
            out.append(cron_d)

    if not out:
        die("No valid weekdays provided.")

    return ",".join(str(x) for x in sorted(out))


# -------------------------
# Schedule interactive preview
# -------------------------
def ask_schedule_with_preview_loop() -> Tuple[str, str]:
    while True:
        stage("Step 1: Choose archive schedule")

        freq_str = prompt("How many times per week? (1-7)")
        if not freq_str.isdigit():
            warn("Frequency must be a number from 1 to 7.")
            continue

        freq = int(freq_str)
        if freq < 1 or freq > 7:
            warn("Frequency out of range (1..7).")
            continue

        if freq == 7:
            time_str = prompt("Enter time (HH:MM, 00:00..23:59)", default="02:10")
            try:
                hh, mm = parse_time_hhmm(time_str)
            except SystemExit:
                continue

            cron_expr = f"{mm} {hh} * * *"
            desc = f"daily at {time_str}"

            stage("Schedule preview")
            print(f"  - Mode:        daily")
            print(f"  - Time:        {time_str}")
            print(f"  - Cron:        {cron_expr}")

            if confirm_yes("Apply this schedule?", default_no=True):
                ok(f"Cron expression applied: {cron_expr}")
                return cron_expr, desc

            warn("Schedule not applied.")
            continue

        days_raw = prompt("Enter weekdays (1=Mon .. 7=Sun), comma-separated")
        time_str = prompt("Enter time (HH:MM, 00:00..23:59)", default="02:10")

        try:
            cron_days = parse_weekdays(days_raw)
            hh, mm = parse_time_hhmm(time_str)
        except SystemExit:
            continue

        cron_expr = f"{mm} {hh} * * {cron_days}"
        desc = f"weekly on days {days_raw} at {time_str}"

        stage("Schedule preview")
        print(f"  - Days input:  {days_raw}")
        print(f"  - Time:        {time_str}")
        print(f"  - Cron:        {cron_expr}")

        if confirm_yes("Apply this schedule?", default_no=True):
            ok(f"Cron expression applied: {cron_expr}")
            return cron_expr, desc

        warn("Schedule not applied.")


# -------------------------
# GPG key handling
# -------------------------
def find_existing_fpr_by_uid(uid: str) -> Optional[str]:
    res = run(["gpg", "--batch", "--with-colons", "--fingerprint", uid], check=False)
    if res.returncode != 0:
        return None
    for line in res.stdout.splitlines():
        if line.startswith("fpr:"):
            parts = line.split(":")
            if len(parts) > 9 and parts[9].strip():
                return parts[9].strip()
    return None


def public_key_exists_in_keyring(fpr: str) -> bool:
    res = run(["gpg", "--batch", "--with-colons", "--fingerprint", fpr], check=False)
    if res.returncode != 0:
        return False
    return any(line.startswith("fpr:") and fpr in line for line in res.stdout.splitlines())
# -------------------------
# GPG key generation
# -------------------------
def generate_key_in_temp_gnupg(tmp_gnupg: Path) -> Tuple[str, dict]:
    stage("Key setup: generating GPG keypair (temporary keyring)")
    env = os.environ.copy()
    env["GNUPGHOME"] = str(tmp_gnupg)
    ensure_dir(tmp_gnupg, 0o700)

    key_params = f"""%no-protection
Key-Type: RSA
Key-Length: 4096
Subkey-Type: RSA
Subkey-Length: 4096
Name-Real: {KEY_NAME}
Name-Comment: {KEY_COMMENT}
Name-Email: {KEY_EMAIL}
Expire-Date: {KEY_EXPIRE}
%commit
"""

    try:
        run(["gpg", "--batch", "--gen-key"], input_text=key_params, env=env)
    except subprocess.CalledProcessError as e:
        die(f"GPG key generation failed: {e.stderr.strip()}")

    res = run(["gpg", "--batch", "--with-colons", "--fingerprint"], env=env)
    fpr = None
    for line in res.stdout.splitlines():
        if line.startswith("fpr:"):
            parts = line.split(":")
            if len(parts) > 9 and parts[9].strip():
                fpr = parts[9].strip()
                break

    if not fpr:
        die("Could not extract fingerprint after key generation.")

    ok(f"Generated fingerprint: {fpr}")
    return fpr, env


def export_keys(tmp_env: dict, fpr: str) -> None:
    stage("Key setup: exporting public/secret keys for SOC")
    ensure_dir(KEY_EXPORT_DIR, 0o700)

    pub = run(["gpg", "--batch", "--yes", "--armor", "--export", fpr], env=tmp_env).stdout
    sec = run(["gpg", "--batch", "--yes", "--armor", "--export-secret-keys", fpr], env=tmp_env).stdout

    PUBKEY_FILE.write_text(pub, encoding="utf-8")
    SECKEY_FILE.write_text(sec, encoding="utf-8")
    FINGERPRINT_FILE.write_text(f"{fpr}\n", encoding="utf-8")

    os.chmod(PUBKEY_FILE, 0o600)
    os.chmod(SECKEY_FILE, 0o600)
    os.chmod(FINGERPRINT_FILE, 0o600)

    ok(f"Public key exported: {PUBKEY_FILE}")
    ok(f"Secret key exported: {SECKEY_FILE}")
    ok(f"Fingerprint saved: {FINGERPRINT_FILE}")


def import_public_key_to_system(pubkey_path: Path, expected_fpr: str) -> str:
    stage("Key setup: importing ONLY public key into system keyring")

    if not file_exists_and_nonempty(pubkey_path):
        die(f"Public key file missing/empty: {pubkey_path}")

    run(["gpg", "--batch", "--yes", "--import", str(pubkey_path)], check=True)

    if not public_key_exists_in_keyring(expected_fpr):
        die("Fingerprint not found in system keyring after public key import.")

    ok(f"Public key imported. Fingerprint: {expected_fpr}")
    return expected_fpr


def ensure_soc_recipient_key() -> Tuple[str, str]:
    stage("Step 2: SOC key (model: one key for SOC)")

    if file_exists_and_nonempty(FINGERPRINT_FILE):
        fpr = FINGERPRINT_FILE.read_text(encoding="utf-8").strip()
        if fpr and public_key_exists_in_keyring(fpr):
            ok(f"Existing SOC key found (fingerprint file): {fpr}")
            if confirm_yes("Reuse existing SOC key?", default_no=False):
                return fpr, "reused"

    fpr_uid = find_existing_fpr_by_uid(SOC_KEY_UID)
    if fpr_uid and public_key_exists_in_keyring(fpr_uid):
        ok(f"Existing SOC key found (UID search): {fpr_uid}")
        if confirm_yes("Reuse existing SOC key?", default_no=False):
            ensure_dir(KEY_EXPORT_DIR, 0o700)
            FINGERPRINT_FILE.write_text(f"{fpr_uid}\n", encoding="utf-8")
            os.chmod(FINGERPRINT_FILE, 0o600)
            return fpr_uid, "reused"

    warn("No existing SOC key found. A new keypair will be generated.")
    if not confirm_yes("Generate a new SOC keypair now?", default_no=True):
        die("Cannot proceed without a recipient key.", code=2)

    with tempfile.TemporaryDirectory(prefix="gnupg-log-archive-") as gnupg_tmp:
        tmp_gnupg = Path(gnupg_tmp)
        fpr_new, tmp_env = generate_key_in_temp_gnupg(tmp_gnupg)
        export_keys(tmp_env, fpr_new)
        import_public_key_to_system(PUBKEY_FILE, fpr_new)
        self_test_full(tmp_env)

    return fpr_new, "generated"


# -------------------------
# Self-tests
# -------------------------
def self_test_encrypt_only(worker_path: Path) -> None:
    stage("Test: encryption-only self-test")
    ensure_dir(LOG_DIR, 0o755)
    ensure_dir(ARCHIVE_DIR, 0o700)

    test_name = f"setup_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    test_path = LOG_DIR / test_name
    test_path.write_text("TEST LINE\n", encoding="utf-8")

    res = subprocess.run(
        [str(worker_path), "--test-file", str(test_path), "--no-restart"],
        text=True,
        capture_output=True
    )

    print(res.stdout.rstrip())
    if res.returncode != 0:
        print(res.stderr.rstrip(), file=sys.stderr)
        die("Encryption-only self-test failed.")

    gpg_files = list(ARCHIVE_DIR.glob("*.gpg"))
    if not gpg_files:
        die("Encryption-only self-test failed: no encrypted file created.")

    ok("Encryption-only self-test OK.")


def self_test_full(tmp_env: dict) -> None:
    stage("Test: full self-test (encrypt + decrypt)")

    ensure_dir(LOG_DIR, 0o755)
    ensure_dir(ARCHIVE_DIR, 0o700)

    test_path = LOG_DIR / "selftest.log"
    test_path.write_text("FULL TEST\n", encoding="utf-8")

    tar_path = ARCHIVE_DIR / "selftest.tar.gz"
    run(["tar", "-czf", str(tar_path), str(test_path)], check=True)

    enc_path = ARCHIVE_DIR / "selftest.tar.gz.gpg"
    run([
        "gpg",
        "--batch", "--yes",
        "--trust-model", "always",
        "--encrypt",
        "--recipient", KEY_EMAIL,
        "-o", str(enc_path),
        str(tar_path),
    ], check=True)

    with tempfile.TemporaryDirectory() as td:
        out_tar = Path(td) / "out.tar.gz"
        run(["gpg", "--batch", "--yes", "--decrypt", "-o", str(out_tar), str(enc_path)],
            env=tmp_env,
            check=True)

        extract_dir = Path(td) / "extract"
        extract_dir.mkdir()
        run(["tar", "-xzf", str(out_tar), "-C", str(extract_dir)], check=True)

        extracted_logs = list(extract_dir.rglob("*.log"))
        if not extracted_logs:
            die("Full self-test failed: no decrypted log found.")

    ok("Full self-test OK.")
# -------------------------
# Install per-agent worker and cron
# -------------------------
def build_worker_and_cron_paths(svc_id: str) -> Tuple[Path, Path, Path]:
    worker_path = WORKER_DIR / f"log_archive_encrypt_{svc_id}.py"
    cron_file = CRON_DIR / f"log-archive-encrypt-{svc_id}"
    cron_log = ARCHIVE_DIR / f"cron_{svc_id}.log"
    return worker_path, cron_file, cron_log


def install_worker(
    worker_path: Path,
    recipient_fpr: str,
    target_service: str,
    dry_run: bool
) -> None:
    stage("Step 3: Installing worker script")

    worker_content = (
        WORKER_TEMPLATE
            .replace("__LOG_DIR__", str(LOG_DIR))
            .replace("__ARCHIVE_DIR__", str(ARCHIVE_DIR))
            .replace("__RECIPIENT_FPR__", recipient_fpr)
            .replace("__TARGET_SERVICE__", target_service)
    )

    if dry_run:
        warn(f"[DRY-RUN] Would ensure directory: {worker_path.parent} (0755)")
        warn(f"[DRY-RUN] Would write worker file: {worker_path}")
        warn(f"[DRY-RUN] Would set mode: 0755")
        return

    # Real execution
    ensure_dir(worker_path.parent, 0o755)
    write_file(worker_path, worker_content, 0o755)

    ok(f"Worker installed: {worker_path}")

def install_cron(
    cron_file: Path,
    cron_expr: str,
    worker_path: Path,
    cron_log: Path,
    dry_run: bool
) -> None:
    stage("Step 4: Installing cron job")

    cron_content = f"""{cron_expr} root {worker_path} --run >> {cron_log} 2>&1
"""

    if dry_run:
        warn(f"[DRY-RUN] Would ensure archive directory: {ARCHIVE_DIR} (0700)")
        warn(f"[DRY-RUN] Would write cron file: {cron_file}")
        warn(f"[DRY-RUN] Cron expression: {cron_expr}")
        warn(f"[DRY-RUN] Cron output log: {cron_log}")
        return

    # Real execution
    ensure_dir(ARCHIVE_DIR, 0o700)
    write_file(cron_file, cron_content, 0o644)

    ok(f"Cron installed: {cron_file}")
    ok(f"Cron output log: {cron_log}")

# -------------------------
# Final report
# -------------------------
def print_report(
    svc_id: str,
    target_service: str,
    schedule_desc: str,
    cron_expr: str,
    worker_path: Path,
    cron_file: Path,
    cron_log: Path,
    recipient_fpr: str,
    key_mode: str
) -> None:
    stage("FINAL REPORT")
    print("")
    print("Agent configuration:")
    print(f" - Service:           {target_service}")
    print(f" - Worker script:     {worker_path}")
    print(f" - Cron file:         {cron_file}")
    print(f" - Cron log:          {cron_log}")
    print(f" - Schedule:          {schedule_desc}")
    print(f" - Cron expression:   {cron_expr}")
    print("")
    print("Archive location:")
    print(f" - Encrypted archives: {ARCHIVE_DIR}/ (files: *.tar.gz.gpg)")
    print("")
    print("SOC recipient key:")
    print(f" - Mode:              {key_mode}")
    print(f" - Fingerprint:       {recipient_fpr}")
    print("")
    print("Integrity model:")
    print(" - Per-line SHA256 hashes inside archive")
    print(" - Archive-level SHA256 stored next to archive")
    print(" - GPG encryption with SOC public key")
    print("")


# -------------------------
# Main
# -------------------------
def main() -> int:
    require_root()
    dry_run = "--dry-run" in sys.argv
    
    if dry_run:
        warn("Running in DRY-RUN mode. No changes will be applied.")

    stage("Step -1: Check dependencies")
    which_or_die("gpg")
    which_or_die("tar")
    which_or_die("systemctl")
    ok("Dependencies OK")

    svc_id, target_service = ask_target_service_id()

    cron_expr, schedule_desc = ask_schedule_with_preview_loop()

    stage("Step 1.5: Prepare directories")
    ensure_dir(LOG_DIR, 0o755)
    ensure_dir(ARCHIVE_DIR, 0o700)
    ensure_dir(KEY_EXPORT_DIR, 0o700)
    ok(f"LOG_DIR: {LOG_DIR}")
    ok(f"ARCHIVE_DIR: {ARCHIVE_DIR}")

    recipient_fpr, key_mode = ensure_soc_recipient_key()

    worker_path, cron_file, cron_log = build_worker_and_cron_paths(svc_id)

    install_worker(worker_path, recipient_fpr, target_service, dry_run)
    install_cron(cron_file, cron_expr, worker_path, cron_log, dry_run)

    if dry_run:
        warn("Self-test skipped (dry-run)")
    else:
        self_test_encrypt_only(worker_path)
    print_report(
        svc_id,
        target_service,
        schedule_desc,
        cron_expr,
        worker_path,
        cron_file,
        cron_log,
        recipient_fpr,
        key_mode
    )

    if key_mode == "generated":
        warn("IMPORTANT: Move the secret key file to SOC and remove it from this server if required.")
        print(f"          {SECKEY_FILE}")

    ok("Setup completed. Cron will run automatically.")
    return 0


if __name__ == "__main__":
    sys.exit(main())
